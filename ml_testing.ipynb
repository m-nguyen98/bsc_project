{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, GRU\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split # for splitting the data into train and test samples\n",
    "from sklearn.metrics import classification_report # for model evaluation metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import seaborn as sns\n",
    "  \n",
    "from sklearn.svm import SVC # for Support Vector Classification model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "import plotly.express as px  # for data visualization\n",
    "import plotly.graph_objects as go # for data visualization\n",
    "\n",
    "plt.style.use('default')\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tnse comps = tsne_comps1 + tsne_comps2 #ictal and interictal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 22, 23, 24]),\n",
       " array([198,  54, 126,  72,  90, 180,  54,  90,  72, 126,  54, 486, 216,\n",
       "        144, 360, 180,  54, 108,  54, 144,  54, 126, 234]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('output.xlsx', index_col=0)\n",
    "\n",
    "vecs_ictal = np.load('tsne_comps1.npy')\n",
    "vecs_interictal = np.load('tsne_comps1_preictal.npy')\n",
    "\n",
    "person_number = np.repeat(np.sort(df[\"patient_number\"].to_numpy()),18)\n",
    "labels_ictal = np.repeat(1,len(person_number))\n",
    "labels_interictal = np.repeat(0, len(person_number))\n",
    "\n",
    "(unique, counts) = np.unique(person_number, return_counts=True)\n",
    "unique, counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Overall Vector with shape (23, x, 18, 42)\n",
    "\n",
    "## OBS: MAYBE NOT USEFUL AFTER ALL...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_vecs(array):\n",
    "    i = 0\n",
    "    all_vecs = []\n",
    "    abxd = 0\n",
    "\n",
    "    for j in range(len(unique)):\n",
    "        temp_list = []\n",
    "        for i in range(counts[j]):\n",
    "            temp_list.append(array[abxd+i])\n",
    "        abxd =+ counts[j]\n",
    "        all_vecs.append(temp_list)\n",
    "        \n",
    "    all_vecs= np.asarray(all_vecs, dtype=object)\n",
    "    return all_vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 = interictal, 1 = ictal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5832, 2) (5832,) (252, 2) (252,)\n"
     ]
    }
   ],
   "source": [
    "def data_splitter(train_data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], test_data=[23]):\n",
    "    X_train, y_train, X_test, y_test = [], [], [], []\n",
    "\n",
    "    for e, per in enumerate(person_number):\n",
    "        if per in train_data:\n",
    "            X_train.append(vecs_interictal[e])\n",
    "            X_train.append(vecs_ictal[e])\n",
    "            y_train.append(labels_interictal[e])\n",
    "            y_train.append(labels_ictal[e])\n",
    "\n",
    "        if per in test_data:\n",
    "            X_test.append(vecs_interictal[e])\n",
    "            X_test.append(vecs_ictal[e])\n",
    "            y_test.append(labels_interictal[e])\n",
    "            y_test.append(labels_ictal[e])\n",
    "            \n",
    "    return np.array(X_train), np.array(y_train), np.array(X_test), np.array(y_test)\n",
    "\n",
    "def legend_without_duplicate_labels(ax):\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    unique = [(h, l) for i, (h, l) in enumerate(zip(handles, labels)) if l not in labels[:i]]\n",
    "    ax.legend(*zip(*unique), bbox_to_anchor=(1.04,1),  loc = \"upper left\", fontsize=15)\n",
    "    \n",
    "def fitting_SVM(train_data, test_data, C, gamma):\n",
    "    # Create training and testing samples\n",
    "    X_train, y_train,  X_test, y_test = data_splitter(train_data, test_data)\n",
    "\n",
    "    # Fit the model\n",
    "    # Note, available kernels: {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’\n",
    "    model = SVC(kernel='rbf', probability=True, C=C, gamma=gamma)\n",
    "    clf = model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict class labels on train data\n",
    "    pred_labels_tr = model.predict(X_train)\n",
    "    # Predict class labels on a test data\n",
    "    pred_labels_te = model.predict(X_test)\n",
    "    \n",
    "    report = confusion_matrix(y_test, pred_labels_te)\n",
    "\n",
    "    # Use score method to get accuracy of the model\n",
    "    print('----- Evaluation on Test Data -----')\n",
    "    score_te = model.score(X_test, y_test)\n",
    "    print('Accuracy Score: ', score_te)\n",
    "    # Look at classification report to evaluate the model\n",
    "    print(classification_report(y_test, pred_labels_te))\n",
    "    clf_report = classification_report(y_test, pred_labels_te, output_dict=True)\n",
    "    print('--------------------------------------------------------')\n",
    "    #report = classification_report(y_test, pred_labels_te, output_dict=True)\n",
    "\n",
    "    print('----- Evaluation on Train Data-----')\n",
    "    score_tr = model.score(X_train, y_train)\n",
    "    print('Accuracy Score: ', score_tr)\n",
    "    # Look at classification report to evaluate the model\n",
    "    print(classification_report(y_train, pred_labels_tr))\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    # Return relevant data for chart plotting\n",
    "    return X_train, X_test, y_train, y_test, clf, report, clf_report\n",
    "\n",
    "\n",
    "def fitting_RF(train_data, test_data):\n",
    "    # Create training and testing samples\n",
    "    X_train, y_train,  X_test, y_test = data_splitter(train_data, test_data)\n",
    "\n",
    "    # Fit the model\n",
    "    # Note, available kernels: {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’\n",
    "    model = RandomForestClassifier(n_estimators = 100)\n",
    "    clf = model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict class labels on train data\n",
    "    pred_labels_tr = model.predict(X_train)\n",
    "    # Predict class labels on a test data\n",
    "    pred_labels_te = model.predict(X_test)\n",
    "    \n",
    "    report = confusion_matrix(y_test, pred_labels_te)\n",
    "\n",
    "    # Use score method to get accuracy of the model\n",
    "    print('----- Evaluation on Test Data -----')\n",
    "    score_te = model.score(X_test, y_test)\n",
    "    print('Accuracy Score: ', score_te)\n",
    "    # Look at classification report to evaluate the model\n",
    "    print(classification_report(y_test, pred_labels_te))\n",
    "    clf_report = classification_report(y_test, pred_labels_te)\n",
    "    clf_report = pd.DataFrame(clf_report).transpose()\n",
    "    print('--------------------------------------------------------')\n",
    "\n",
    "    print('----- Evaluation on Train Data-----')\n",
    "    score_tr = model.score(X_train, y_train)\n",
    "    print('Accuracy Score: ', score_tr)\n",
    "    # Look at classification report to evaluate the model\n",
    "    print(classification_report(y_train, pred_labels_tr))\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    # Return relevant data for chart plotting\n",
    "    return X_train, X_test, y_train, y_test, clf, report, clf_report\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = data_splitter()\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.898989898989899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       198\n",
      "           1       0.92      0.87      0.90       198\n",
      "\n",
      "    accuracy                           0.90       396\n",
      "   macro avg       0.90      0.90      0.90       396\n",
      "weighted avg       0.90      0.90      0.90       396\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9251137102014295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      3078\n",
      "           1       0.93      0.92      0.92      3078\n",
      "\n",
      "    accuracy                           0.93      6156\n",
      "   macro avg       0.93      0.93      0.93      6156\n",
      "weighted avg       0.93      0.93      0.93      6156\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8425925925925926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85        54\n",
      "           1       0.91      0.76      0.83        54\n",
      "\n",
      "    accuracy                           0.84       108\n",
      "   macro avg       0.85      0.84      0.84       108\n",
      "weighted avg       0.85      0.84      0.84       108\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9234947237740534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      3222\n",
      "           1       0.93      0.92      0.92      3222\n",
      "\n",
      "    accuracy                           0.92      6444\n",
      "   macro avg       0.92      0.92      0.92      6444\n",
      "weighted avg       0.92      0.92      0.92      6444\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8809523809523809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       126\n",
      "           1       0.94      0.82      0.87       126\n",
      "\n",
      "    accuracy                           0.88       252\n",
      "   macro avg       0.89      0.88      0.88       252\n",
      "weighted avg       0.89      0.88      0.88       252\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9282539682539682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      3150\n",
      "           1       0.94      0.92      0.93      3150\n",
      "\n",
      "    accuracy                           0.93      6300\n",
      "   macro avg       0.93      0.93      0.93      6300\n",
      "weighted avg       0.93      0.93      0.93      6300\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9513888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95        72\n",
      "           1       0.96      0.94      0.95        72\n",
      "\n",
      "    accuracy                           0.95       144\n",
      "   macro avg       0.95      0.95      0.95       144\n",
      "weighted avg       0.95      0.95      0.95       144\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9215043695380774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      3204\n",
      "           1       0.93      0.91      0.92      3204\n",
      "\n",
      "    accuracy                           0.92      6408\n",
      "   macro avg       0.92      0.92      0.92      6408\n",
      "weighted avg       0.92      0.92      0.92      6408\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.86      0.81        90\n",
      "           1       0.84      0.74      0.79        90\n",
      "\n",
      "    accuracy                           0.80       180\n",
      "   macro avg       0.80      0.80      0.80       180\n",
      "weighted avg       0.80      0.80      0.80       180\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9240426867545511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      3186\n",
      "           1       0.93      0.92      0.92      3186\n",
      "\n",
      "    accuracy                           0.92      6372\n",
      "   macro avg       0.92      0.92      0.92      6372\n",
      "weighted avg       0.92      0.92      0.92      6372\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.7555555555555555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.74       180\n",
      "           1       0.73      0.80      0.77       180\n",
      "\n",
      "    accuracy                           0.76       360\n",
      "   macro avg       0.76      0.76      0.76       360\n",
      "weighted avg       0.76      0.76      0.76       360\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9291020671834626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      3096\n",
      "           1       0.94      0.92      0.93      3096\n",
      "\n",
      "    accuracy                           0.93      6192\n",
      "   macro avg       0.93      0.93      0.93      6192\n",
      "weighted avg       0.93      0.93      0.93      6192\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8981481481481481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.81      0.89        54\n",
      "           1       0.84      0.98      0.91        54\n",
      "\n",
      "    accuracy                           0.90       108\n",
      "   macro avg       0.91      0.90      0.90       108\n",
      "weighted avg       0.91      0.90      0.90       108\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9205462445685909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      3222\n",
      "           1       0.93      0.91      0.92      3222\n",
      "\n",
      "    accuracy                           0.92      6444\n",
      "   macro avg       0.92      0.92      0.92      6444\n",
      "weighted avg       0.92      0.92      0.92      6444\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9277777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93        90\n",
      "           1       0.92      0.93      0.93        90\n",
      "\n",
      "    accuracy                           0.93       180\n",
      "   macro avg       0.93      0.93      0.93       180\n",
      "weighted avg       0.93      0.93      0.93       180\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9204331450094162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      3186\n",
      "           1       0.93      0.91      0.92      3186\n",
      "\n",
      "    accuracy                           0.92      6372\n",
      "   macro avg       0.92      0.92      0.92      6372\n",
      "weighted avg       0.92      0.92      0.92      6372\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8680555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.87        72\n",
      "           1       0.91      0.82      0.86        72\n",
      "\n",
      "    accuracy                           0.87       144\n",
      "   macro avg       0.87      0.87      0.87       144\n",
      "weighted avg       0.87      0.87      0.87       144\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.924625468164794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      3204\n",
      "           1       0.93      0.92      0.92      3204\n",
      "\n",
      "    accuracy                           0.92      6408\n",
      "   macro avg       0.92      0.92      0.92      6408\n",
      "weighted avg       0.92      0.92      0.92      6408\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8174603174603174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       126\n",
      "           1       0.82      0.82      0.82       126\n",
      "\n",
      "    accuracy                           0.82       252\n",
      "   macro avg       0.82      0.82      0.82       252\n",
      "weighted avg       0.82      0.82      0.82       252\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9255555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      3150\n",
      "           1       0.93      0.92      0.93      3150\n",
      "\n",
      "    accuracy                           0.93      6300\n",
      "   macro avg       0.93      0.93      0.93      6300\n",
      "weighted avg       0.93      0.93      0.93      6300\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8981481481481481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        54\n",
      "           1       1.00      0.80      0.89        54\n",
      "\n",
      "    accuracy                           0.90       108\n",
      "   macro avg       0.92      0.90      0.90       108\n",
      "weighted avg       0.92      0.90      0.90       108\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9225636250775916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      3222\n",
      "           1       0.93      0.92      0.92      3222\n",
      "\n",
      "    accuracy                           0.92      6444\n",
      "   macro avg       0.92      0.92      0.92      6444\n",
      "weighted avg       0.92      0.92      0.92      6444\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9619341563786008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       486\n",
      "           1       0.98      0.94      0.96       486\n",
      "\n",
      "    accuracy                           0.96       972\n",
      "   macro avg       0.96      0.96      0.96       972\n",
      "weighted avg       0.96      0.96      0.96       972\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9161290322580645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      2790\n",
      "           1       0.92      0.91      0.92      2790\n",
      "\n",
      "    accuracy                           0.92      5580\n",
      "   macro avg       0.92      0.92      0.92      5580\n",
      "weighted avg       0.92      0.92      0.92      5580\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9537037037037037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95       216\n",
      "           1       0.94      0.97      0.95       216\n",
      "\n",
      "    accuracy                           0.95       432\n",
      "   macro avg       0.95      0.95      0.95       432\n",
      "weighted avg       0.95      0.95      0.95       432\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9179738562091503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      3060\n",
      "           1       0.92      0.91      0.92      3060\n",
      "\n",
      "    accuracy                           0.92      6120\n",
      "   macro avg       0.92      0.92      0.92      6120\n",
      "weighted avg       0.92      0.92      0.92      6120\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91       144\n",
      "           1       0.89      0.95      0.92       144\n",
      "\n",
      "    accuracy                           0.92       288\n",
      "   macro avg       0.92      0.92      0.92       288\n",
      "weighted avg       0.92      0.92      0.92       288\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9201787994891443\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      3132\n",
      "           1       0.93      0.91      0.92      3132\n",
      "\n",
      "    accuracy                           0.92      6264\n",
      "   macro avg       0.92      0.92      0.92      6264\n",
      "weighted avg       0.92      0.92      0.92      6264\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9847222222222223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       360\n",
      "           1       0.99      0.98      0.98       360\n",
      "\n",
      "    accuracy                           0.98       720\n",
      "   macro avg       0.98      0.98      0.98       720\n",
      "weighted avg       0.98      0.98      0.98       720\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9122085048010974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      2916\n",
      "           1       0.92      0.90      0.91      2916\n",
      "\n",
      "    accuracy                           0.91      5832\n",
      "   macro avg       0.91      0.91      0.91      5832\n",
      "weighted avg       0.91      0.91      0.91      5832\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9833333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       180\n",
      "           1       0.98      0.99      0.98       180\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9171511627906976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92      3096\n",
      "           1       0.92      0.91      0.92      3096\n",
      "\n",
      "    accuracy                           0.92      6192\n",
      "   macro avg       0.92      0.92      0.92      6192\n",
      "weighted avg       0.92      0.92      0.92      6192\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95        54\n",
      "           1       0.96      0.93      0.94        54\n",
      "\n",
      "    accuracy                           0.94       108\n",
      "   macro avg       0.95      0.94      0.94       108\n",
      "weighted avg       0.95      0.94      0.94       108\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9210117939168219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      3222\n",
      "           1       0.93      0.91      0.92      3222\n",
      "\n",
      "    accuracy                           0.92      6444\n",
      "   macro avg       0.92      0.92      0.92      6444\n",
      "weighted avg       0.92      0.92      0.92      6444\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9768518518518519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       108\n",
      "           1       1.00      0.95      0.98       108\n",
      "\n",
      "    accuracy                           0.98       216\n",
      "   macro avg       0.98      0.98      0.98       216\n",
      "weighted avg       0.98      0.98      0.98       216\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9195075757575758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      3168\n",
      "           1       0.93      0.91      0.92      3168\n",
      "\n",
      "    accuracy                           0.92      6336\n",
      "   macro avg       0.92      0.92      0.92      6336\n",
      "weighted avg       0.92      0.92      0.92      6336\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9351851851851852\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        54\n",
      "           1       1.00      0.87      0.93        54\n",
      "\n",
      "    accuracy                           0.94       108\n",
      "   macro avg       0.94      0.94      0.93       108\n",
      "weighted avg       0.94      0.94      0.93       108\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9219428926132837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      3222\n",
      "           1       0.93      0.91      0.92      3222\n",
      "\n",
      "    accuracy                           0.92      6444\n",
      "   macro avg       0.92      0.92      0.92      6444\n",
      "weighted avg       0.92      0.92      0.92      6444\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9236111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93       144\n",
      "           1       0.98      0.87      0.92       144\n",
      "\n",
      "    accuracy                           0.92       288\n",
      "   macro avg       0.93      0.92      0.92       288\n",
      "weighted avg       0.93      0.92      0.92       288\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9220945083014048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      3132\n",
      "           1       0.93      0.92      0.92      3132\n",
      "\n",
      "    accuracy                           0.92      6264\n",
      "   macro avg       0.92      0.92      0.92      6264\n",
      "weighted avg       0.92      0.92      0.92      6264\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9259259259259259\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        54\n",
      "           1       0.93      0.93      0.93        54\n",
      "\n",
      "    accuracy                           0.93       108\n",
      "   macro avg       0.93      0.93      0.93       108\n",
      "weighted avg       0.93      0.93      0.93       108\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9216325263811297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      3222\n",
      "           1       0.93      0.91      0.92      3222\n",
      "\n",
      "    accuracy                           0.92      6444\n",
      "   macro avg       0.92      0.92      0.92      6444\n",
      "weighted avg       0.92      0.92      0.92      6444\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9206349206349206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92       126\n",
      "           1       0.88      0.98      0.92       126\n",
      "\n",
      "    accuracy                           0.92       252\n",
      "   macro avg       0.93      0.92      0.92       252\n",
      "weighted avg       0.93      0.92      0.92       252\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9203174603174603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      3150\n",
      "           1       0.93      0.91      0.92      3150\n",
      "\n",
      "    accuracy                           0.92      6300\n",
      "   macro avg       0.92      0.92      0.92      6300\n",
      "weighted avg       0.92      0.92      0.92      6300\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9145299145299145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       234\n",
      "           1       0.89      0.94      0.92       234\n",
      "\n",
      "    accuracy                           0.91       468\n",
      "   macro avg       0.92      0.91      0.91       468\n",
      "weighted avg       0.92      0.91      0.91       468\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.9229125575279421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92      3042\n",
      "           1       0.93      0.91      0.92      3042\n",
      "\n",
      "    accuracy                           0.92      6084\n",
      "   macro avg       0.92      0.92      0.92      6084\n",
      "weighted avg       0.92      0.92      0.92      6084\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "conf_matrix_list_of_arrays = []\n",
    "\n",
    "df = {\"precision\": [], \"recall\": [], \"f1-score\": [], \"support\": []}\n",
    "\n",
    "\n",
    "for i in range(1,25):\n",
    "    # Leave one out model \n",
    "    if i == 21:\n",
    "        continue\n",
    "    test_data = [i]\n",
    "    \n",
    "    train_data = [*range(1, 25, 1)]\n",
    "    train_data.remove(21)\n",
    "    train_data.remove(i)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, clf, report, clf_report = fitting_SVM(train_data, test_data, 1, 'scale')\n",
    "    accuracy_train.append(clf.score(X_train, y_train))\n",
    "    accuracy_test.append(clf.score(X_test,y_test))\n",
    "    df[\"precision\"].append(clf_report[\"0\"][\"precision\"]), df[\"recall\"].append(clf_report[\"0\"][\"recall\"])\n",
    "    df[\"f1-score\"].append(clf_report[\"0\"][\"f1-score\"]), df[\"support\"].append(clf_report[\"0\"][\"support\"])\n",
    "    conf_matrix_list_of_arrays.append(report)\n",
    "    cm = report \n",
    "    \n",
    "    #ax= plt.subplot()\n",
    "    #sns.heatmap(cm, annot=True, cmap=\"crest\", fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "    # labels, title and ticks\n",
    "    #ax.set_xlabel('Predicted Labels');ax.set_ylabel('True Labels'); \n",
    "    #ax.set_title(f'Confusion Matrix for Patient {i}'); \n",
    "    #ax.xaxis.set_ticklabels(['Inter-Ictal', 'Ictal']); ax.yaxis.set_ticklabels(['Inter-Ictal', 'Ictal']);\n",
    "    #plt.savefig(f'conf_matrix_p{i}.png')\n",
    "    #plt.clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.10090991551297"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([ a*100 for a in df['precision']])\n",
    "## 10 seconds before annotation vs 4 seconds after "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[93.43065693430657,\n",
       " 70.0,\n",
       " 78.88888888888889,\n",
       " 92.3076923076923,\n",
       " 79.36507936507937,\n",
       " 79.3103448275862,\n",
       " 85.0,\n",
       " 74.02597402597402,\n",
       " 91.30434782608695,\n",
       " 79.51807228915662,\n",
       " 75.51020408163265,\n",
       " 94.6268656716418,\n",
       " 88.31168831168831,\n",
       " 91.83673469387756,\n",
       " 87.36842105263159,\n",
       " 78.94736842105263,\n",
       " 84.44444444444444,\n",
       " 88.37209302325581,\n",
       " 87.87878787878788,\n",
       " 96.22641509433963,\n",
       " 85.1063829787234,\n",
       " 73.91304347826086,\n",
       " 82.53968253968253]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ a*100 for a in df['precision']] \n",
    "## 4 seconds before annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([78.53535353535354,\n",
       "  75.0,\n",
       "  73.80952380952381,\n",
       "  75.69444444444444,\n",
       "  74.44444444444444,\n",
       "  73.88888888888889,\n",
       "  78.70370370370371,\n",
       "  80.55555555555556,\n",
       "  79.86111111111111,\n",
       "  80.95238095238095,\n",
       "  80.55555555555556,\n",
       "  71.09053497942386,\n",
       "  79.62962962962963,\n",
       "  78.81944444444444,\n",
       "  75.83333333333333,\n",
       "  78.88888888888889,\n",
       "  75.92592592592592,\n",
       "  76.85185185185185,\n",
       "  78.70370370370371,\n",
       "  71.875,\n",
       "  72.22222222222221,\n",
       "  78.57142857142857,\n",
       "  79.48717948717949],\n",
       " [77.14424951267057,\n",
       "  77.1880819366853,\n",
       "  77.23809523809524,\n",
       "  77.20037453183521,\n",
       "  77.22849968612681,\n",
       "  77.24483204134367,\n",
       "  77.1725636250776,\n",
       "  77.04017576898933,\n",
       "  77.02871410736579,\n",
       "  76.93650793650794,\n",
       "  77.01738050900062,\n",
       "  77.59856630824373,\n",
       "  77.00980392156863,\n",
       "  76.9955300127714,\n",
       "  77.400548696845,\n",
       "  76.95413436692506,\n",
       "  77.25015518311608,\n",
       "  77.24116161616162,\n",
       "  77.01738050900062,\n",
       "  77.28288633461047,\n",
       "  77.28119180633148,\n",
       "  77.07936507936508,\n",
       "  76.90664036817883])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test, result_train ### 4 seconds after annotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7715029735203547, 0.7695217847995626)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracy_train), np.mean(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7681399125746199"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df['f1-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.7777777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       198\n",
      "           1       0.79      0.76      0.77       198\n",
      "\n",
      "    accuracy                           0.78       396\n",
      "   macro avg       0.78      0.78      0.78       396\n",
      "weighted avg       0.78      0.78      0.78       396\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m train_data \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m24\u001b[39m, \u001b[39m1\u001b[39m)]\n\u001b[1;32m      4\u001b[0m train_data\u001b[39m.\u001b[39mremove(\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m X_train, X_test, y_train, y_test, clf, report \u001b[39m=\u001b[39m fitting_SVM(train_data, test_data, \u001b[39m1\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mscale\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m accuracy\u001b[39m.\u001b[39mappend(clf\u001b[39m.\u001b[39mscore(X_test,y_test))\n\u001b[1;32m      8\u001b[0m conf_matrix_list_of_arrays\u001b[39m.\u001b[39mappend(report)\n",
      "Cell \u001b[0;32mIn [4], line 51\u001b[0m, in \u001b[0;36mfitting_SVM\u001b[0;34m(train_data, test_data, C, gamma)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m#report = classification_report(y_test, pred_labels_te, output_dict=True)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m----- Evaluation on Train Data-----\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m score_tr \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mscore(X_train, y_train)\n\u001b[1;32m     52\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy Score: \u001b[39m\u001b[39m'\u001b[39m, score_tr)\n\u001b[1;32m     53\u001b[0m \u001b[39m# Look at classification report to evaluate the model\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:500\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    478\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 500\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X), sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:624\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    622\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_function(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    623\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 624\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[1;32m    625\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:344\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    342\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_for_predict(X)\n\u001b[1;32m    343\u001b[0m predict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse_predict \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dense_predict\n\u001b[0;32m--> 344\u001b[0m \u001b[39mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:361\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mX.shape[1] = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m should be equal to \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    356\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mthe number of samples at training time\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    357\u001b[0m                          (X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_[\u001b[39m0\u001b[39m]))\n\u001b[1;32m    359\u001b[0m svm_type \u001b[39m=\u001b[39m LIBSVM_IMPL\u001b[39m.\u001b[39mindex(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl)\n\u001b[0;32m--> 361\u001b[0m \u001b[39mreturn\u001b[39;00m libsvm\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m    362\u001b[0m     X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_vectors_, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_support,\n\u001b[1;32m    363\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dual_coef_, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_intercept_,\n\u001b[1;32m    364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_probA, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_probB, svm_type\u001b[39m=\u001b[39;49msvm_type, kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[1;32m    365\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree, coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0, gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[1;32m    366\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_data = [1]\n",
    "\n",
    "train_data = [*range(1, 24, 1)]\n",
    "train_data.remove(1)\n",
    "\n",
    "X_train, X_test, y_train, y_test, clf, report = fitting_SVM(train_data, test_data, 1, 'scale')\n",
    "accuracy.append(clf.score(X_test,y_test))\n",
    "conf_matrix_list_of_arrays.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  76.95, Sensitivity:  74.65, Specificity:  78.17\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_of_conf_matrix_arrays = (np.mean(conf_matrix_list_of_arrays, axis=0))\n",
    "cm = mean_of_conf_matrix_arrays.astype(int)\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, cmap=\"crest\", fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted Labels');ax.set_ylabel('True Labels'); \n",
    "ax.set_title('Average Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Inter-Ictal', 'Ictal']); ax.yaxis.set_ticklabels(['Inter-Ictal', 'Ictal']);\n",
    "\n",
    "acc = np.mean(accuracy_test)*100\n",
    "mean_cm = mean_of_conf_matrix_arrays.astype(int)\n",
    "TP, TN, FN, FP = mean_cm[1][1], mean_cm[0][0], mean_cm[1][0], mean_cm[0][1]\n",
    "\n",
    "\n",
    "\n",
    "sensitivity = (TP/(TP+FN))*100\n",
    "specificity = (TN/(TN+FP))*100\n",
    "\n",
    "print(f\"Accuracy: {acc: .2f}, Sensitivity: {sensitivity: .2f}, Specificity: {specificity: .2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8763888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88       360\n",
      "           1       0.91      0.83      0.87       360\n",
      "\n",
      "    accuracy                           0.88       720\n",
      "   macro avg       0.88      0.88      0.88       720\n",
      "weighted avg       0.88      0.88      0.88       720\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2916\n",
      "           1       1.00      1.00      1.00      2916\n",
      "\n",
      "    accuracy                           1.00      5832\n",
      "   macro avg       1.00      1.00      1.00      5832\n",
      "weighted avg       1.00      1.00      1.00      5832\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91        54\n",
      "           1       0.89      0.94      0.92        54\n",
      "\n",
      "    accuracy                           0.92       108\n",
      "   macro avg       0.92      0.92      0.92       108\n",
      "weighted avg       0.92      0.92      0.92       108\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3222\n",
      "           1       1.00      1.00      1.00      3222\n",
      "\n",
      "    accuracy                           1.00      6444\n",
      "   macro avg       1.00      1.00      1.00      6444\n",
      "weighted avg       1.00      1.00      1.00      6444\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8253968253968254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       126\n",
      "           1       0.84      0.81      0.82       126\n",
      "\n",
      "    accuracy                           0.83       252\n",
      "   macro avg       0.83      0.83      0.83       252\n",
      "weighted avg       0.83      0.83      0.83       252\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3150\n",
      "           1       1.00      1.00      1.00      3150\n",
      "\n",
      "    accuracy                           1.00      6300\n",
      "   macro avg       1.00      1.00      1.00      6300\n",
      "weighted avg       1.00      1.00      1.00      6300\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8680555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87        72\n",
      "           1       0.87      0.86      0.87        72\n",
      "\n",
      "    accuracy                           0.87       144\n",
      "   macro avg       0.87      0.87      0.87       144\n",
      "weighted avg       0.87      0.87      0.87       144\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3204\n",
      "           1       1.00      1.00      1.00      3204\n",
      "\n",
      "    accuracy                           1.00      6408\n",
      "   macro avg       1.00      1.00      1.00      6408\n",
      "weighted avg       1.00      1.00      1.00      6408\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8611111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.81      0.85        90\n",
      "           1       0.83      0.91      0.87        90\n",
      "\n",
      "    accuracy                           0.86       180\n",
      "   macro avg       0.86      0.86      0.86       180\n",
      "weighted avg       0.86      0.86      0.86       180\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3186\n",
      "           1       1.00      1.00      1.00      3186\n",
      "\n",
      "    accuracy                           1.00      6372\n",
      "   macro avg       1.00      1.00      1.00      6372\n",
      "weighted avg       1.00      1.00      1.00      6372\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       180\n",
      "           1       0.96      0.94      0.95       180\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3096\n",
      "           1       1.00      1.00      1.00      3096\n",
      "\n",
      "    accuracy                           1.00      6192\n",
      "   macro avg       1.00      1.00      1.00      6192\n",
      "weighted avg       1.00      1.00      1.00      6192\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9166666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92        54\n",
      "           1       0.96      0.87      0.91        54\n",
      "\n",
      "    accuracy                           0.92       108\n",
      "   macro avg       0.92      0.92      0.92       108\n",
      "weighted avg       0.92      0.92      0.92       108\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.999844816883923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3222\n",
      "           1       1.00      1.00      1.00      3222\n",
      "\n",
      "    accuracy                           1.00      6444\n",
      "   macro avg       1.00      1.00      1.00      6444\n",
      "weighted avg       1.00      1.00      1.00      6444\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8944444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90        90\n",
      "           1       0.92      0.87      0.89        90\n",
      "\n",
      "    accuracy                           0.89       180\n",
      "   macro avg       0.90      0.89      0.89       180\n",
      "weighted avg       0.90      0.89      0.89       180\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3186\n",
      "           1       1.00      1.00      1.00      3186\n",
      "\n",
      "    accuracy                           1.00      6372\n",
      "   macro avg       1.00      1.00      1.00      6372\n",
      "weighted avg       1.00      1.00      1.00      6372\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87        72\n",
      "           1       0.86      0.89      0.88        72\n",
      "\n",
      "    accuracy                           0.88       144\n",
      "   macro avg       0.88      0.88      0.87       144\n",
      "weighted avg       0.88      0.88      0.87       144\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3204\n",
      "           1       1.00      1.00      1.00      3204\n",
      "\n",
      "    accuracy                           1.00      6408\n",
      "   macro avg       1.00      1.00      1.00      6408\n",
      "weighted avg       1.00      1.00      1.00      6408\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9087301587301587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       126\n",
      "           1       0.94      0.87      0.91       126\n",
      "\n",
      "    accuracy                           0.91       252\n",
      "   macro avg       0.91      0.91      0.91       252\n",
      "weighted avg       0.91      0.91      0.91       252\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3150\n",
      "           1       1.00      1.00      1.00      3150\n",
      "\n",
      "    accuracy                           1.00      6300\n",
      "   macro avg       1.00      1.00      1.00      6300\n",
      "weighted avg       1.00      1.00      1.00      6300\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8611111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86        54\n",
      "           1       0.84      0.89      0.86        54\n",
      "\n",
      "    accuracy                           0.86       108\n",
      "   macro avg       0.86      0.86      0.86       108\n",
      "weighted avg       0.86      0.86      0.86       108\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3222\n",
      "           1       1.00      1.00      1.00      3222\n",
      "\n",
      "    accuracy                           1.00      6444\n",
      "   macro avg       1.00      1.00      1.00      6444\n",
      "weighted avg       1.00      1.00      1.00      6444\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8878600823045267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       486\n",
      "           1       0.93      0.84      0.88       486\n",
      "\n",
      "    accuracy                           0.89       972\n",
      "   macro avg       0.89      0.89      0.89       972\n",
      "weighted avg       0.89      0.89      0.89       972\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2790\n",
      "           1       1.00      1.00      1.00      2790\n",
      "\n",
      "    accuracy                           1.00      5580\n",
      "   macro avg       1.00      1.00      1.00      5580\n",
      "weighted avg       1.00      1.00      1.00      5580\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8796296296296297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       216\n",
      "           1       0.89      0.86      0.88       216\n",
      "\n",
      "    accuracy                           0.88       432\n",
      "   macro avg       0.88      0.88      0.88       432\n",
      "weighted avg       0.88      0.88      0.88       432\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3060\n",
      "           1       1.00      1.00      1.00      3060\n",
      "\n",
      "    accuracy                           1.00      6120\n",
      "   macro avg       1.00      1.00      1.00      6120\n",
      "weighted avg       1.00      1.00      1.00      6120\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9340277777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       144\n",
      "           1       0.94      0.93      0.93       144\n",
      "\n",
      "    accuracy                           0.93       288\n",
      "   macro avg       0.93      0.93      0.93       288\n",
      "weighted avg       0.93      0.93      0.93       288\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3132\n",
      "           1       1.00      1.00      1.00      3132\n",
      "\n",
      "    accuracy                           1.00      6264\n",
      "   macro avg       1.00      1.00      1.00      6264\n",
      "weighted avg       1.00      1.00      1.00      6264\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9111111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91       360\n",
      "           1       0.89      0.94      0.91       360\n",
      "\n",
      "    accuracy                           0.91       720\n",
      "   macro avg       0.91      0.91      0.91       720\n",
      "weighted avg       0.91      0.91      0.91       720\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2916\n",
      "           1       1.00      1.00      1.00      2916\n",
      "\n",
      "    accuracy                           1.00      5832\n",
      "   macro avg       1.00      1.00      1.00      5832\n",
      "weighted avg       1.00      1.00      1.00      5832\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       180\n",
      "           1       0.85      0.81      0.83       180\n",
      "\n",
      "    accuracy                           0.83       360\n",
      "   macro avg       0.83      0.83      0.83       360\n",
      "weighted avg       0.83      0.83      0.83       360\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3096\n",
      "           1       1.00      1.00      1.00      3096\n",
      "\n",
      "    accuracy                           1.00      6192\n",
      "   macro avg       1.00      1.00      1.00      6192\n",
      "weighted avg       1.00      1.00      1.00      6192\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84        54\n",
      "           1       0.85      0.81      0.83        54\n",
      "\n",
      "    accuracy                           0.83       108\n",
      "   macro avg       0.83      0.83      0.83       108\n",
      "weighted avg       0.83      0.83      0.83       108\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3222\n",
      "           1       1.00      1.00      1.00      3222\n",
      "\n",
      "    accuracy                           1.00      6444\n",
      "   macro avg       1.00      1.00      1.00      6444\n",
      "weighted avg       1.00      1.00      1.00      6444\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88       108\n",
      "           1       0.89      0.86      0.87       108\n",
      "\n",
      "    accuracy                           0.88       216\n",
      "   macro avg       0.88      0.88      0.87       216\n",
      "weighted avg       0.88      0.88      0.87       216\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3168\n",
      "           1       1.00      1.00      1.00      3168\n",
      "\n",
      "    accuracy                           1.00      6336\n",
      "   macro avg       1.00      1.00      1.00      6336\n",
      "weighted avg       1.00      1.00      1.00      6336\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8796296296296297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88        54\n",
      "           1       0.86      0.91      0.88        54\n",
      "\n",
      "    accuracy                           0.88       108\n",
      "   macro avg       0.88      0.88      0.88       108\n",
      "weighted avg       0.88      0.88      0.88       108\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.999844816883923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3222\n",
      "           1       1.00      1.00      1.00      3222\n",
      "\n",
      "    accuracy                           1.00      6444\n",
      "   macro avg       1.00      1.00      1.00      6444\n",
      "weighted avg       1.00      1.00      1.00      6444\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.9027777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       144\n",
      "           1       0.95      0.85      0.90       144\n",
      "\n",
      "    accuracy                           0.90       288\n",
      "   macro avg       0.91      0.90      0.90       288\n",
      "weighted avg       0.91      0.90      0.90       288\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3132\n",
      "           1       1.00      1.00      1.00      3132\n",
      "\n",
      "    accuracy                           1.00      6264\n",
      "   macro avg       1.00      1.00      1.00      6264\n",
      "weighted avg       1.00      1.00      1.00      6264\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8472222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85        72\n",
      "           1       0.86      0.83      0.85        72\n",
      "\n",
      "    accuracy                           0.85       144\n",
      "   macro avg       0.85      0.85      0.85       144\n",
      "weighted avg       0.85      0.85      0.85       144\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3204\n",
      "           1       1.00      1.00      1.00      3204\n",
      "\n",
      "    accuracy                           1.00      6408\n",
      "   macro avg       1.00      1.00      1.00      6408\n",
      "weighted avg       1.00      1.00      1.00      6408\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8425925925925926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.83        54\n",
      "           1       0.81      0.89      0.85        54\n",
      "\n",
      "    accuracy                           0.84       108\n",
      "   macro avg       0.85      0.84      0.84       108\n",
      "weighted avg       0.85      0.84      0.84       108\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  0.999844816883923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3222\n",
      "           1       1.00      1.00      1.00      3222\n",
      "\n",
      "    accuracy                           1.00      6444\n",
      "   macro avg       1.00      1.00      1.00      6444\n",
      "weighted avg       1.00      1.00      1.00      6444\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Test Data -----\n",
      "Accuracy Score:  0.8492063492063492\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85       126\n",
      "           1       0.84      0.87      0.85       126\n",
      "\n",
      "    accuracy                           0.85       252\n",
      "   macro avg       0.85      0.85      0.85       252\n",
      "weighted avg       0.85      0.85      0.85       252\n",
      "\n",
      "--------------------------------------------------------\n",
      "----- Evaluation on Train Data-----\n",
      "Accuracy Score:  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3150\n",
      "           1       1.00      1.00      1.00      3150\n",
      "\n",
      "    accuracy                           1.00      6300\n",
      "   macro avg       1.00      1.00      1.00      6300\n",
      "weighted avg       1.00      1.00      1.00      6300\n",
      "\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "conf_matrix_list_of_arrays = []\n",
    "\n",
    "\n",
    "for i in range(1,24):\n",
    "    # Leave one out model \n",
    "    test_data = [i]\n",
    "    \n",
    "    train_data = [*range(1, 24, 1)]\n",
    "    train_data.remove(i)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, clf, report = fitting_RF(train_data, test_data)\n",
    "    accuracy.append(clf.score(X_test,y_test))\n",
    "    conf_matrix_list_of_arrays.append(report)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_of_conf_matrix_arrays = (np.mean(conf_matrix_list_of_arrays, axis=0))\n",
    "cm = mean_of_conf_matrix_arrays.astype(int)\n",
    "\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, cmap=\"crest\", fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted Labels');ax.set_ylabel('True Labels'); \n",
    "ax.set_title('Average Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Inter-Ictal', 'Ictal']); ax.yaxis.set_ticklabels(['Inter-Ictal', 'Ictal']);\n",
    "\n",
    "#acc = np.mean(accuracy)\n",
    "mean_cm = mean_of_conf_matrix_arrays.astype(int)\n",
    "TP, TN, FN, FP = mean_cm[1][1], mean_cm[0][0], mean_cm[1][0], mean_cm[0][1]\n",
    "\n",
    "\n",
    "\n",
    "sensitivity = TP/(TP+FN)\n",
    "specificity = TN/(TN+FP)\n",
    "\n",
    "#print(f\"Accuracy: {acc: .2f}, Sensitivity: {sensitivity: .2f}, Specificity: {specificity: .2f}\")\n",
    "plt.savefig('filename.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af404f03f415c453f2d2cd106887cf66d2956cab21fc1be97213bea542ee67de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
